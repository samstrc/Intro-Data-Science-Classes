{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MATH 300 - Tools for Data Science \n",
    "# Exercises for: Linear Regression 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Conceptual Questions\n",
    "\n",
    "## Task 1.1\n",
    "\n",
    "Suppose we have a data set with five predictors, $X_1$ = GPA, $X_2$ =IQ, $X_3$ = Level (1 for College and 0 for High School), $X_4$ = Interaction between GPA and IQ, and $X_5$ = Interaction between GPA and Level. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get\n",
    "$\\beta_0 = 50$, $\\beta_1 = 20$, $\\beta_2 = 0.07$, $\\beta_3 = 35$, $\\beta_4 = 0.01$, $\\beta_5 = −10$. \n",
    "\n",
    "(a) Which answer is correct, and why?\n",
    "\n",
    "i. For a fixed value of IQ and GPA, high school graduates earn more, on average, than college graduates.\n",
    "\n",
    "ii. For a fixed value of IQ and GPA, college graduates earn more, on average, than high school graduates.\n",
    "\n",
    "iii. For a fixed value of IQ and GPA, high school graduates earn more, on average, than college graduates provided that the\n",
    "GPA is high enough.\n",
    "\n",
    "iv. For a fixed value of IQ and GPA, college graduates earn more, on average, than high school graduates provided that the GPA is high enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:**\n",
    "\n",
    "The answer is iii. My work is included in my response zip file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Predict the salary of a college graduate with IQ of 110 and a GPA of 4.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We predict that a college graduate with a IQ of 110 will make 137.1k a year.\n"
     ]
    }
   ],
   "source": [
    "b_0 = 50\n",
    "b_1 = 20\n",
    "b_2 = 0.07\n",
    "b_3 = 35\n",
    "b_4 = 0.01\n",
    "b_5 = -10\n",
    "\n",
    "prediction = b_0 + (b_1 * 4) + (b_2 * 110) + b_3 + (b_4 * (4.0 * 110)) + (b_5 * 4)\n",
    "print(f\"We predict that a college graduate with a IQ of 110 will make {prediction}k a year.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) True or false: Since the coefficient for the GPA/IQ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:** False, the coefficient means nothing in regards to statistical significance. Yes, the coefficient is small, but it is still a meaningful calculation in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2\n",
    "\n",
    "I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. $Y=\\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 +\\epsilon$.\n",
    "\n",
    "(a) Suppose that the true relationship between X and Y is linear, i.e. $Y=\\beta_0 + \\beta_1 X +\\epsilon$. Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:** The cubic regression model can fit training data as well as the linear model, but $\\beta_2$ and $\\beta_3$ will likely be very close to zero if the true relationship is linear. However, the cubic regression model will overfit to noise. Overfitting will minimize the training RSS close to 0. A complex model will always fit training data better than a simpler model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Answer (a) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:** While the cubic regression model can fit training data very well, it will struggle generalizing to fresh data in comparison to the linear model. Thus, the RSS value will be much higher than the linear model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Suppose that the true relationship between X and Y is not linear, but we don’t know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the\n",
    "other, would we expect them to be the same, or is there not enough information to tell? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:** Since the cubic regression model includes all terms of the linear model and adds additional flexibility, its training RSS will always be equal to or lower than that of the linear regression. Even if the true relationship is not cubic, the cubic model can better capture nonlinear patterns in the training data, reducing the RSS. Thus, the training RSS for the cubic regression will be lower than or equal to the training RSS for the linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Answer (c) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:** If the true relationship between X and Y isn't linear, the test RSS for the cubic regression may be lower or higher than that of the linear regression, depending on how well it captures the true pattern. If the cubic model provides a better approximation of the true relationship, it will have a lower test RSS. However, if it overfits the training data by capturing noise, it may have a higher test RSS than the linear model. I would say there is not enough information to determine which test RSS will be lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3\n",
    "\n",
    "Explain what cross validation is, how it is implemented, and why we would want to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:** Cross-validation is a method used to assess a model’s performance by splitting the data into multiple training and validation sets. It is implemented by dividing the dataset into k folds, training the model on k-1 folds, and evaluating it on the remaining fold, repeating this process k times. The final performance metric is the average of all iterations. The goal of cross-validation  is to obtain a more reliable estimate of a model’s generalization ability, reduce overfitting, and select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2: Applied Questions - Analysis of the credit dataset \n",
    "\n",
    "Recall the 'Credit' dataset introduced in class. \n",
    "This dataset consists of some credit card information for 400 people. \n",
    "\n",
    "First import the data and convert income to thousands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Student</th>\n",
       "      <th>Married</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14891.0</td>\n",
       "      <td>3606</td>\n",
       "      <td>283</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106025.0</td>\n",
       "      <td>6645</td>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Asian</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104593.0</td>\n",
       "      <td>7075</td>\n",
       "      <td>514</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148924.0</td>\n",
       "      <td>9504</td>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55882.0</td>\n",
       "      <td>4897</td>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>12096.0</td>\n",
       "      <td>4100</td>\n",
       "      <td>307</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>13364.0</td>\n",
       "      <td>3838</td>\n",
       "      <td>296</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>African American</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>57872.0</td>\n",
       "      <td>4171</td>\n",
       "      <td>321</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>37728.0</td>\n",
       "      <td>2525</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>18701.0</td>\n",
       "      <td>5524</td>\n",
       "      <td>415</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income  Limit  Rating  Cards  Age  Education  Gender Student Married  \\\n",
       "1     14891.0   3606     283      2   34         11    Male      No     Yes   \n",
       "2    106025.0   6645     483      3   82         15  Female     Yes     Yes   \n",
       "3    104593.0   7075     514      4   71         11    Male      No      No   \n",
       "4    148924.0   9504     681      3   36         11  Female      No      No   \n",
       "5     55882.0   4897     357      2   68         16    Male      No     Yes   \n",
       "..        ...    ...     ...    ...  ...        ...     ...     ...     ...   \n",
       "396   12096.0   4100     307      3   32         13    Male      No     Yes   \n",
       "397   13364.0   3838     296      5   65         17    Male      No      No   \n",
       "398   57872.0   4171     321      5   67         12  Female      No     Yes   \n",
       "399   37728.0   2525     192      1   44         13    Male      No     Yes   \n",
       "400   18701.0   5524     415      5   64          7  Female      No      No   \n",
       "\n",
       "            Ethnicity  Balance  \n",
       "1           Caucasian      333  \n",
       "2               Asian      903  \n",
       "3               Asian      580  \n",
       "4               Asian      964  \n",
       "5           Caucasian      331  \n",
       "..                ...      ...  \n",
       "396         Caucasian      560  \n",
       "397  African American      480  \n",
       "398         Caucasian      138  \n",
       "399         Caucasian        0  \n",
       "400             Asian      966  \n",
       "\n",
       "[400 rows x 11 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports and setup\n",
    "\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm     #Last lecture: used statsmodels.formula.api.ols() for OLS\n",
    "from sklearn import linear_model         #Last lecture: used sklearn.linear_model.LinearRegression() for OLS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "# Import data from Credit.csv file\n",
    "credit = pd.read_csv('credit_copy.csv',index_col=0) #load data\n",
    "credit[\"Income\"] = credit[\"Income\"].map(lambda x: 1000*x) # Replace income data with the income data * 1000 (element wise)\n",
    "credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: A First Regression Model\n",
    "\n",
    "**Exercise:** First regress Limit on Rating: \n",
    "$$\n",
    "\\text{Limit} = \\beta_0 + \\beta_1 \\text{Rating}. \n",
    "$$\n",
    "Since credit ratings are primarily used by banks to determine credit limits, we expect that Rating is very predictive for Limit, so this regression should be very good. \n",
    "\n",
    "Use the 'ols' function from the statsmodels python library. What is the $R^2$ value? What are $H_0$ and $H_A$ for the associated hypothesis test and what is the $p$-value? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Value: 0.9938\n",
      "P-value for Rating coefficient: 0.0000e+00\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Limit   R-squared:                       0.994\n",
      "Model:                            OLS   Adj. R-squared:                  0.994\n",
      "Method:                 Least Squares   F-statistic:                 6.348e+04\n",
      "Date:                Mon, 10 Mar 2025   Prob (F-statistic):               0.00\n",
      "Time:                        14:20:11   Log-Likelihood:                -2649.1\n",
      "No. Observations:                 400   AIC:                             5302.\n",
      "Df Residuals:                     398   BIC:                             5310.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   -542.9282     22.850    -23.760      0.000    -587.851    -498.006\n",
      "Rating        14.8716      0.059    251.949      0.000      14.756      14.988\n",
      "==============================================================================\n",
      "Omnibus:                        6.887   Durbin-Watson:                   2.080\n",
      "Prob(Omnibus):                  0.032   Jarque-Bera (JB):                4.980\n",
      "Skew:                          -0.145   Prob(JB):                       0.0829\n",
      "Kurtosis:                       2.537   Cond. No.                         970.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Fit the linear regression model using formula notation\n",
    "model = sm.ols('Limit ~ Rating', data=credit).fit()\n",
    "\n",
    "# Extract R^2 value\n",
    "r_squared = model.rsquared\n",
    "\n",
    "# Extract p-value for Rating coefficient\n",
    "p_value = model.pvalues[\"Rating\"]\n",
    "\n",
    "# Print results\n",
    "print(f\"R^2 Value: {r_squared:.4f}\")\n",
    "print(f\"P-value for Rating coefficient: {p_value:.4e}\")\n",
    "\n",
    "# Display the full regression summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:**\n",
    "\n",
    "$H_0$: The rating coefficient is not statistically significant (0).\n",
    "$H_A$: The rating coefficient is statistically significant (not 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.2: Predicting Limit without Rating \n",
    "\n",
    "Since Rating and Limit are almost the same variable, next we'll forget about Rating and just try to predict Limit from the real-valued variables (non-categorical variables): Income, Cards, Age, Education, Balance. \n",
    "\n",
    "**Exercise:** Develop a multilinear regression model to predict Rating. Interpret the results. \n",
    "\n",
    "For now, just focus on the real-valued variables (Income, Cards, Age, Education, Balance)\n",
    "and ignore the categorical variables (Gender, Student, Married, Ethnicity). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Value: 0.9409\n",
      "\n",
      "P-values for predictors:\n",
      " Intercept     6.570730e-31\n",
      "Income       6.371109e-123\n",
      "Cards         6.105378e-01\n",
      "Age           2.307941e-01\n",
      "Education     3.678292e-01\n",
      "Balance      1.635432e-158\n",
      "dtype: float64 \n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Rating   R-squared:                       0.941\n",
      "Model:                            OLS   Adj. R-squared:                  0.940\n",
      "Method:                 Least Squares   F-statistic:                     1255.\n",
      "Date:                Mon, 10 Mar 2025   Prob (F-statistic):          1.68e-239\n",
      "Time:                        14:32:02   Log-Likelihood:                -2017.9\n",
      "No. Observations:                 400   AIC:                             4048.\n",
      "Df Residuals:                     394   BIC:                             4072.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    143.6089     11.377     12.622      0.000     121.241     165.977\n",
      "Income         0.0022   6.21e-05     34.987      0.000       0.002       0.002\n",
      "Cards          0.7105      1.394      0.510      0.611      -2.030       3.451\n",
      "Age            0.1347      0.112      1.200      0.231      -0.086       0.355\n",
      "Education     -0.5475      0.607     -0.902      0.368      -1.741       0.646\n",
      "Balance        0.2132      0.005     45.367      0.000       0.204       0.222\n",
      "==============================================================================\n",
      "Omnibus:                       64.518   Durbin-Watson:                   1.880\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               93.640\n",
      "Skew:                          -1.179   Prob(JB):                     4.64e-21\n",
      "Kurtosis:                       3.247   Cond. No.                     3.45e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.45e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define predictor variables and response variable\n",
    "predictors = [\"Income\", \"Cards\", \"Age\", \"Education\", \"Balance\"]\n",
    "response = \"Rating\"\n",
    "\n",
    "# Fit the multiple linear regression model using formula notation\n",
    "multi_model = sm.ols(f\"{response} ~ {' + '.join(predictors)}\", data=credit).fit()\n",
    "\n",
    "# Extract key results\n",
    "r_squared = multi_model.rsquared  # R^2 value\n",
    "p_values = multi_model.pvalues     # p-values for predictors\n",
    "summary = multi_model.summary()    # Full regression summary\n",
    "\n",
    "# Print results\n",
    "print(f\"R^2 Value: {r_squared:.4f}\\n\")\n",
    "print(\"P-values for predictors:\\n\", p_values, \"\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Which independent variables are good/bad predictors? What is the best overall model?\n",
    "\n",
    "**Your observations:** It seems that cards, age, and education are not statistically significant predictors. However, income and balance are highly significant. The best model would be to predict rating using income and balance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.3: Incorporating Categorical Variables Into Regression Models\n",
    "\n",
    "Now consider the binary categorical variables which we mapped to integer 0, 1 values in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "credit[\"Gender_num\"] = credit[\"Gender\"].map({' Male':0, 'Female':1})\n",
    "credit[\"Student_num\"] = credit[\"Student\"].map({'Yes':1, 'No':0})\n",
    "credit[\"Married_num\"] = credit[\"Married\"].map({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Can you improve the model you developed in Activity 2 by incorporating one or more of these variables?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Rating   R-squared:                       0.974\n",
      "Model:                            OLS   Adj. R-squared:                  0.974\n",
      "Method:                 Least Squares   F-statistic:                     4964.\n",
      "Date:                Mon, 10 Mar 2025   Prob (F-statistic):          1.09e-313\n",
      "Time:                        14:40:01   Log-Likelihood:                -1853.1\n",
      "No. Observations:                 400   AIC:                             3714.\n",
      "Df Residuals:                     396   BIC:                             3730.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept     149.3993      2.178     68.584      0.000     145.117     153.682\n",
      "Income          0.0021   4.04e-05     51.522      0.000       0.002       0.002\n",
      "Balance         0.2334      0.003     72.888      0.000       0.227       0.240\n",
      "Student_num   -98.3619      4.343    -22.647      0.000    -106.901     -89.823\n",
      "==============================================================================\n",
      "Omnibus:                       47.985   Durbin-Watson:                   1.931\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               61.873\n",
      "Skew:                          -0.914   Prob(JB):                     3.67e-14\n",
      "Kurtosis:                       3.607   Cond. No.                     1.99e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.99e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define the best model with significant predictors\n",
    "final_predictors = [\"Income\", \"Balance\", \"Student_num\"]\n",
    "response = \"Rating\"\n",
    "\n",
    "# Fit the multiple linear regression model\n",
    "final_model = sm.ols(f\"{response} ~ {' + '.join(final_predictors)}\", data=credit).fit()\n",
    "\n",
    "# Print model summary\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:** The model's $R^2$ value does seem to be a bit higher with this model!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
